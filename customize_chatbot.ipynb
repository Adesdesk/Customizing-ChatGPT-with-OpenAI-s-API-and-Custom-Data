{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WJki-8BTOjQj"
      },
      "source": [
        "Welcome to the TrekBot Colab notebook! This notebook behaves exactly like a jupyter notebook. Let's dive right in!\n",
        "\n",
        "First step: put the JSON data file here inside a folder called \"data\":\n",
        "https://www.kaggle.com/datasets/gjbroughton/start-trek-scripts?resource=download\n",
        "\n",
        "Now we'll install a few necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDa-3B1j6RXn",
        "outputId": "d4a8c13b-8f4f-4151-ec82-3c64b9b12436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BuN-ORGzYP5n"
      },
      "source": [
        "Next we import the packages we'll need.\n",
        "\n",
        "\n",
        "**pandas** is a package that allows us to conveniently store and manipulate data in a data structure known as a Dataframe. (This is similar to a Dataframe in R, for those familiar with R.) It’s a very common tool for anyone doing data science in python.\n",
        "\n",
        "**sklearn** is the package formally called “scikit-learn”, and contains a wide range of statistical and machine learning methods. It’s another very common package for data scientists in python.\n",
        "\n",
        "**numpy** is python’s main numeric library, and allows us to do things like work with arrays, matrices, dot products, etc.\n",
        "\n",
        "**json** is a package for interacting with json files. Our data is formatted as a single json file, so this is useful for us here.\n",
        "\n",
        "**os** helps us with file management and command-line commands.\n",
        "\n",
        "**openai** is a package containing functions that allow us to easily make API calls to OpenAI’s models in python.\n",
        "\n",
        "Finally, we import **cosine_similarity** from sklearn, since it’s a specialized function that we need today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nv9fSpa1-SmS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import openai\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "\n",
        "CHUNK_SIZE = 600\n",
        "OVERLAP = 20"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i73a2SiNYWz9"
      },
      "source": [
        "Remember the OpenAI API key you created? Copy and paste it in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YbnFGeS-e5Z",
        "outputId": "04addb97-c359-4ed3-e251-9b34e6d100ce"
      },
      "outputs": [],
      "source": [
        "openai.api_key = input(\"Paste your OpenAI API key here and hit enter:\");"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0Z-KFYYbuv"
      },
      "source": [
        "Here's what the model is doing: we have a long piece of text that we want ChatGPT to be able to answer questions about. We first break that text up into chunks containing 600 words (technically called “tokens”), where each chunk overlaps 20 words with the following chunk. We then send these chunks to OpenAI to obtain their embeddings. When we ask a question about our text, we find the question’s embedding, and use cosine similarity to find the chunk of text that is closest to our question. We then send a query to ChatGPT that includes our original question, as well as the chunk of text as context.\n",
        "\n",
        "We loop over all the chunks, and send each one to OpenAI, get back the embedding, and then write a new line to the Dataframe df. Note that we are casting the embedding response (a string) to a numpy array. We do this because we will be doing numerical operations on the embedding in just a moment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nR3icJ14_Di0"
      },
      "outputs": [],
      "source": [
        "scripts = json.load(open(\"adeola_custom_text/adeola_sample_text.json\", encoding='ascii'))\n",
        "text = scripts['Vusi_writes']['LinkedIn_post']\n",
        "text_list = text.split()\n",
        "chunks = [text_list[i:i+CHUNK_SIZE] for i in range(0, len(text_list), CHUNK_SIZE-OVERLAP)]\n",
        "df = pd.DataFrame(columns=['chunk', 'gpt_raw', 'embedding'])\n",
        "for chunk in chunks:\n",
        "    f = openai.Embedding.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=\" \".join(chunk),\n",
        "    )\n",
        "    df.loc[len(df.index)] = (chunk, f, np.array(f['data'][0]['embedding']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "fh6mCPlNOtgc",
        "outputId": "bb075731-2d73-4e05-fbb6-0d3bd2983642"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-09e0a34c-f790-4f6f-8903-8b16648b663e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>gpt_raw</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[AI, Robot, as, CEO:, Company, Shatters, Stock...</td>\n",
              "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
              "      <td>[-0.00732967397198081, -0.045327551662921906, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e0a34c-f790-4f6f-8903-8b16648b663e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09e0a34c-f790-4f6f-8903-8b16648b663e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09e0a34c-f790-4f6f-8903-8b16648b663e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               chunk  \\\n",
              "0  [AI, Robot, as, CEO:, Company, Shatters, Stock...   \n",
              "\n",
              "                                             gpt_raw  \\\n",
              "0  {'object': 'list', 'data': [{'object': 'embedd...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.00732967397198081, -0.045327551662921906, ...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nOYoYbnYY17L"
      },
      "source": [
        "Now, let’s define our query and get its embedding. Our query is a simple question: who was the captain of the Excalibur? A bit of context: in this episode, a small detail is that one of the crew members was assigned to command a ship for this one episode only, and it’s a minor detail in the plot of the episode. In fact, if you ask ChatGPT this question without giving it the script, it doesn’t know the answer. We’ll see that with the right chunk of text, identified by cosine similarity, ChatGPT can answer correctly.\n",
        "\n",
        "We calculate the cosine distance from our query to each chunk, and save the chunk that is most similar to a variable called context_chunk.\n",
        "\n",
        "Finally, we assemble the full query, including the chunk we identified, and send it to ChatGPT via the API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "53974KA0_EuM"
      },
      "outputs": [],
      "source": [
        "query = \"Tang Yu, an AI robot, was appointed as CEO of which company?\"\n",
        "f = openai.Embedding.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=query\n",
        ")\n",
        "query_embedding = np.array(f['data'][0]['embedding'])\n",
        "\n",
        "similarity = []\n",
        "for arr in df['embedding'].values:\n",
        "    similarity.extend(cosine_similarity(query_embedding.reshape(1, -1), arr.reshape(1, -1)))\n",
        "context_chunk = chunks[np.argmax(similarity)]\n",
        "\n",
        "query_to_send = \"CONTEXT: \" + \" \".join(context_chunk) + \"\\n\\n\" + query\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt= query_to_send,\n",
        "  max_tokens=100,\n",
        "  temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_a-RUeMQ53O",
        "outputId": "17f9d507-a0ab-412f-cf29-a711d9eb2127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONTEXT: AI Robot as CEO: Company Shatters Stock Market Records with Unprecedented Profits. In a ground-breaking move, a gaming company in Hong Kong appointed an AI robot as its CEO, signalling the growing potential of artificial intelligence to assume human roles. This decision took place even before the widespread recognition of AI chatbots like ChatGPT. Remarkably, this innovative move led to the company achieving unprecedented profits in the stock market. In an awe-inspiring move, Tang Yu, an AI robot, was appointed as CEO of NetDragon Websoft. The business not only achieved unparalleled success in Hong Kong's stock market but also witnessed an astonishing surge in its stock value. TheAI chatbot was recognised by the industry as a pioneer in implementing AI to improve operational productivity and change corporate administration. Among Tang Yu's responsibilities at NetDragon Websoft were examining high-level statistics, evaluating risks, and nurturing an effective workplace. As the first business leader to operate continuously without payment, Tang Yu set a new standard. In naming the AI robot CEO, the company claimed it would cultivate talent and ensure a productive workplace for all employees. A fascinating aspect of the AI program was that it helped the business make money. According to reports, the company outperformed the Hang Seng Index, which measures the performance of Hong Kong's largest corporations. According to Hustle's website, which monitors stock market success, the company's shares have grown 10% since six months ago. At the market's current valuation, the company is worth approximately HK$9 billion, or $1.1 billion. There are numerous factors that could explain the increase in value of the company, including increased demand for its goods and services, a better financial performance, and favourable news about the business. Dejian Liu, Chairman of NetDragon, said AI is the managerial technology of the future for businesses, referring to the AI CEO. In order to change their business practices, they are committed to embracing AI. Tang Yu's appointment symbolises their commitment to this objective. According to the individual, they intend to continue developing their algorithms to support Tang Yu in creating an open, participatory, and visible management system. Furthermore, they intend to evolve into a metaverse-based working community, allowing them to draw in more talent from around the world and achieve more ambitious goals. The Hustle asked ChatGPT, the powerful AI chatbot that is currently rekindling fears of automation, to ruminate on the likelihood of a great CEO replacement. It admitted it wasn’t up for the job yet — at least not “in the near future.” Reading this info on the rise of an AI-powered CEO, it's impossible not to ponder the implications of having an AI as our boss. Would it be a surreal and futuristic experience, or a daunting prospect that challenges our notions of leadership and human interaction? The ever-evolving landscape of technology continues to push the boundaries of what was once considered possible, leaving us to contemplate the role of AI in shaping our professional lives. As we navigate this new era, we're left wondering: How would you feel with an AI as your boss?\n",
            "\n",
            "Tang Yu, an AI robot, was appointed as CEO of which company?\n"
          ]
        }
      ],
      "source": [
        "print(query_to_send)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "riOblNiGZA5C"
      },
      "source": [
        "Let's test our bot. Did it get it right? Execute the cell below to find out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i9zCaYV_G9k",
        "outputId": "54f0c29a-d605-480e-e6bc-1f77ab36de72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tang Yu was appointed as CEO of NetDragon Websoft, a gaming company in Hong Kong.\n"
          ]
        }
      ],
      "source": [
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yEei7bCiBvc6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
